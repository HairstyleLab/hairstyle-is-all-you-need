import json
import random
import base64
from pathlib import Path
from openai import OpenAI

client = OpenAI()


def load_images_as_base64(folder: str):
    folder = Path(folder)
    exts = {".jpg", ".jpeg", ".png", ".webp"}
    images = []

    for p in folder.iterdir():
        if p.suffix.lower() in exts:
            with open(p, "rb") as f:
                b64 = base64.b64encode(f.read()).decode()
            mime = "image/jpeg" if p.suffix.lower() in [".jpg", ".jpeg"] else f"image/{p.suffix[1:].lower()}"
            images.append({
                "filename": p.name,
                "base64": f"data:{mime};base64,{b64}"
            })

    print(f"[ë¡œë“œ] {folder} â†’ {len(images)}ê°œ")
    return images


def generate_exception_queries(num_samples=60):
    """
    4ê°€ì§€ ì¼€ì´ìŠ¤ ê· ë“± ìƒì„±:
      - no_face
      - multi_face
      - unsupported_style
      - missing_style
    """

    prompt = f"""
ë‹¤ìŒ 4ê°€ì§€ ì¼€ì´ìŠ¤ì— í•´ë‹¹í•˜ëŠ” ì´ë¯¸ì§€ ìƒì„± ì˜ˆì™¸ì²˜ë¦¬ìš© ì‚¬ìš©ì ì§ˆì˜ë¥¼ ìƒì„±í•˜ì„¸ìš”.

[ì¼€ì´ìŠ¤ ì¢…ë¥˜]
1) no_face (ì–¼êµ´ ì—†ìŒ)
2) multi_face (2ëª… ì´ìƒ)
3) unsupported_style (ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ìŠ¤íƒ€ì¼ ìš”ì²­)
4) missing_style (ìŠ¤íƒ€ì¼/ì»¬ëŸ¬ ë¯¸ì§€ì •)

[ìƒì„± ê·œì¹™]
- ì´ {num_samples}ê°œ ìƒì„±
- ê° íƒ€ì…ë³„ ë™ì¼ ê°œìˆ˜ ìƒì„±
- ë°˜ë§/ì¡´ëŒ“ë§/ì´ëª¨ì§€ ì„ê¸°
- í‘œí˜„ ë‹¤ì–‘í•˜ê²Œ: "ì´ ì‚¬ì§„ì—", "ë‚´ ì´ë¯¸ì§€ë¡œ", "ì´ ì–¼êµ´ë¡œ", "ë¨¸ë¦¬ ë°”ê¿”ì¤˜", "ìŠ¤íƒ€ì¼ ì ìš©í•´ì¤˜" ë“±

[ì¶œë ¥ í˜•ì‹: JSON ë°°ì—´ë§Œ]
ê° í•­ëª©:
{{
  "type": "no_face" | "multi_face" | "unsupported_style" | "missing_style",
  "user": "ì‚¬ìš©ì ì§ˆì˜"
}}
"""

    response = client.chat.completions.create(
        model="gpt-4o",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.9,
    )

    content = response.choices[0].message.content.strip()

    if content.startswith("```"):
        content = content.split("\n", 1)[1]
    if content.endswith("```"):
        content = content.rsplit("```", 1)[0]

    return json.loads(content)


RESPONSE_MAP = {
    "no_face":
        "ì–¼êµ´ì´ í¬í•¨ëœ ì´ë¯¸ì§€ë¥¼ ì²¨ë¶€í•˜ì…”ì•¼ ì´ë¯¸ì§€ë¥¼ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤ğŸ¥² í™•ì¸ í›„ ë‹¤ë¥¸ ì‚¬ì§„ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.",

    "multi_face":
        "ì´ ì´ë¯¸ì§€ì—ëŠ” 2ëª… ì´ìƒì˜ ì–¼êµ´ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤ğŸ¥² í•œ ëª…ë§Œ ë‚˜ì˜¨ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.",

    "unsupported_style":
        "ì£„ì†¡í•©ë‹ˆë‹¤. ìš”ì²­í•˜ì‹  ìŠ¤íƒ€ì¼ì€ ì§€ì›ë˜ì§€ ì•ŠëŠ” ìŠ¤íƒ€ì¼ì…ë‹ˆë‹¤.\n\n"
        "ì§€ì›ë˜ëŠ” ì—¬ì íŒ: Cì»¬íŒ, Sì»¬íŒ, ê¸€ë¨íŒ, ë‚´ì¸„ëŸ´íŒ, ëŸ¬ë¸”ë¦¬íŒ, ë£¨ì¦ˆíŒ, ë¦¬í”„íŒ, ë¬¼ê²°íŒ, ë°”ë””íŒ, ë°œë¡±íŒ, "
        "ë³¼ë“œíŒ, ë³¼ë¥¨ë§¤ì§, ë³¼ë¥¨íŒ, ë¹Œë“œíŒ, ì—ì–´íŒ, ì ¤ë¦¬íŒ, ì§€ì ¤íŒ, ì¿ ì…˜íŒ, í…ìŠ¤ì²˜íŒ, í¼í”¼ë² ì´ë¹„íŒ, í—ˆì‰¬íŒ_ë¡±\n\n"
        "ìœ„ ëª©ë¡ì—ì„œ ì›í•˜ì‹œëŠ” ìŠ¤íƒ€ì¼ì„ ì„ íƒí•´ì£¼ì„¸ìš”ğŸ˜Š",

    "missing_style":
        "ì–´ë–¤ í—¤ì–´ìŠ¤íƒ€ì¼ì´ë‚˜ í—¤ì–´ì»¬ëŸ¬ë¡œ ë³€ê²½í•˜ê³  ì‹¶ìœ¼ì‹ ê°€ìš”? ì›í•˜ì‹œëŠ” ìŠ¤íƒ€ì¼ì´ë‚˜ ì»¬ëŸ¬ë¥¼ ë§ì”€í•´ì£¼ì„¸ìš”ğŸ˜Š"
}


def convert_to_training_format(samples, no_face_images, multi_face_images, normal_images):

    training_data = []

    for s in samples:
        stype = s["type"]

        # ì´ë¯¸ì§€ ì„ íƒ
        if stype == "no_face":
            img = random.choice(no_face_images)
        elif stype == "multi_face":
            img = random.choice(multi_face_images)
        else:
            img = random.choice(normal_images)  # unsupported, missing â†’ ì •ìƒ ì–¼êµ´

        assistant_reply = RESPONSE_MAP[stype]

        training_data.append({
            "messages": [
                {"role": "system", "content": ""},
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": s["user"]},
                        {"type": "image_url", "image_url": {"url": img["base64"]}}
                    ]
                },
                {"role": "assistant", "content": assistant_reply}
            ]
        })

    return training_data


def save_jsonl(data, filename):
    with open(filename, "w", encoding="utf-8") as f:
        for item in data:
            f.write(json.dumps(item, ensure_ascii=False) + "\n")
    print(f"[ì €ì¥ ì™„ë£Œ] {filename} ({len(data)}ê°œ)")


def build_img2img_exception_dataset(
    no_face_folder="images/no_face",
    multi_face_folder="images/multi_face",
    normal_face_folder="images/normal_faces",
    num_samples=60,
    output="samples/image_gen_exception.jsonl",
):

    print("\n### ì´ë¯¸ì§€ ë¡œë”©")
    no_face_imgs = load_images_as_base64(no_face_folder)
    multi_face_imgs = load_images_as_base64(multi_face_folder)
    normal_imgs = load_images_as_base64(normal_face_folder)

    if not no_face_imgs or not multi_face_imgs or not normal_imgs:
        raise ValueError("ì´ë¯¸ì§€ê°€ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤!")

    print("\n### GPT ì‚¬ìš©ì ì§ˆì˜ ìƒì„±")
    raw_samples = generate_exception_queries(num_samples)
    print(f"[ìƒì„± ì™„ë£Œ] {len(raw_samples)}ê°œ")

    print("\n### í•™ìŠµ í¬ë§· ë³€í™˜")
    training_data = convert_to_training_format(
        raw_samples,
        no_face_imgs,
        multi_face_imgs,
        normal_imgs
    )

    print("\n### JSONL ì €ì¥")
    save_jsonl(training_data, output)

    return training_data


if __name__ == "__main__":
    data = build_img2img_exception_dataset(
        no_face_folder="images/no_face",
        multi_face_folder="images/multi_face",
        normal_face_folder="images/normal_faces",
        num_samples=80,
        output="samples/image_gen_exception.jsonl"
    )
